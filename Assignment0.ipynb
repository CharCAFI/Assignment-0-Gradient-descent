{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 0\n",
    "\n",
    "**Name:** -- Carlos Alberto Fregoso Iturria --\n",
    "\n",
    "**email:** -- carlos.fregoso8429@alumnos.udg.mx --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with this assignment, you need to install the required Python modules. These modules are essential for running the code and generating the plots. Use the following commands to install numpy and matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy:** A library for numerical computing in Python, providing support for arrays and mathematical functions.\n",
    "\n",
    "**matplotlib:** A plotting library used for creating static, interactive, and animated visualizations in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully installing these modules and ensuring no errors occur, you can proceed to import them into your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory on the Gradient Descent algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Gradient Descent algorithm is a popular optimization method used to minimize a function by iteratively moving towards the function's local minimum. This technique is widely used in machine learning and optimization problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Explained:\n",
    "\n",
    "**Objective:** Find the minimum value of a function.\n",
    "\n",
    "**How It Works:** Start from an initial guess and iteratively adjust the guess in the direction opposite to the gradient (the direction of the steepest increase) to reduce the function value.\n",
    "\n",
    "**Mathematical Basis:** The gradient provides the slope of the function at a given point. By moving in the opposite direction of this slope, you aim to find a point where the function's value is minimized.\n",
    "\n",
    "## Gradient Descent Implementation\n",
    "\n",
    "Here's how the Gradient Descent algorithm is implemented in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gradient descent function\n",
    "def gradient_descent(f, grad_f, x_init, y_init, learning_rate, num_iterations):\n",
    "    x, y = x_init, y_init\n",
    "    trajectory = [(x, y)]\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        grad_x, grad_y = grad_f(x, y)\n",
    "        x -= learning_rate * grad_x\n",
    "        y -= learning_rate * grad_y\n",
    "        trajectory.append((x, y))\n",
    "    \n",
    "    return x, y, trajectory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f:** The function to be optimized.\n",
    "\n",
    "**grad_f:** A function that computes the gradient of f.\n",
    "\n",
    "**x_init, y_init:** Initial values for the variables.\n",
    "\n",
    "**learning_rate:** The step size used to update the variables.\n",
    "\n",
    "**num_iterations:** The number of iterations to run the gradient descent algorithm.\n",
    "\n",
    "**trajectory:** A list to store the coordinates of each point visited during optimization.\n",
    "\n",
    "The gradient descent function updates the point (x, y) by moving in the direction of the negative gradient scaled by the learning rate, and it tracks the path taken in the trajectory list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gradient of the sphere function\n",
    "def grad_f_sphere(x, y):\n",
    "    return (2*x, 2*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the gradient of the sphere function, which consists of the partial derivatives with respect to x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for gradient descent\n",
    "x_init, y_init = 10, 10\n",
    "learning_rate = 0.1\n",
    "num_iterations = 100\n",
    "\n",
    "# Perform gradient descent\n",
    "x_min, y_min, trajectory = gradient_descent(f_sphere, grad_f_sphere, x_init, y_init, learning_rate, num_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**x_init, y_init:** Starting point for the optimization.\n",
    "\n",
    "**learning_rate:** Determines how big each step is during optimization.\n",
    "\n",
    "**num_iterations:** Number of steps to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the code implements the Gradient Descent algorithm to find the minimum of a function. The gradient_descent function takes as input the function to be optimized (f), its gradient (grad_f), the initial point (x_init, y_init), the learning rate, and the number of iterations. It iteratively updates the point by moving in the opposite direction of the gradient, scaled by the learning rate, and records each point in the trajectory list. The function returns the final optimized coordinates (x_min, y_min) and the trajectory of points visited during the optimization. Additionally, the gradient of the sphere function is defined by grad_f_sphere, which returns the partial derivatives 2x and 2y. The gradient descent algorithm is then run with specified parameters to find the minimum of the sphere function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results\n",
    "\n",
    "To visualize the results of the gradient descent, we plot both the surface of the function and the path taken by the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, Z, cmap='coolwarm', alpha=0.5)\n",
    "trajectory = np.array(trajectory)\n",
    "ax.plot(trajectory[:,0], trajectory[:,1], f_sphere(trajectory[:,0], trajectory[:,1]), 'r-o')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fig:** Creates a new figure for plotting.\n",
    "\n",
    "**ax:** Adds a 3D subplot to the figure.\n",
    "\n",
    "**ax.plot_surface:** Plots the surface of the sphere function using a color map (coolwarm) and 50% transparency.\n",
    "\n",
    "**ax.plot:** Draws the trajectory of the gradient descent algorithm in red circles ('r-o').\n",
    "\n",
    "**ax.set_xlabel, ax.set_ylabel, ax.set_zlabel:** Adds labels to the x, y, and z axes.\n",
    "\n",
    "This visualization helps to understand how the function behaves and how the gradient descent algorithm converges to the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates a 3D visualization of the previously defined function f_sphere(x, y) = x^2 + y^2. It creates a figure and a set of 3D axes using matplotlib. The ax.plot_surface function is then used to plot the surface of the function with the X, Y, and Z meshes, applying a coolwarm color map and 50% transparency (alpha=0.5). Additionally, the minimum point of the function (0,0,0) is marked with a red circular marker using ax.scatter. Finally, axis labels for x, y, and z are added for clarity, and the plot is displayed with plt.show()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "\n",
    "#Load Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the gradient descent function\n",
    "def gradient_descent(f, grad_f, x_init, y_init, learning_rate, num_iterations):\n",
    "    x, y = x_init, y_init\n",
    "    trajectory = [(x, y)]\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        grad_x, grad_y = grad_f(x, y)\n",
    "        x -= learning_rate * grad_x\n",
    "        y -= learning_rate * grad_y\n",
    "        trajectory.append((x, y))\n",
    "    \n",
    "    return x, y, trajectory\n",
    "\n",
    "# Define the gradient of the sphere function\n",
    "def grad_f_sphere(x, y):\n",
    "    return (2*x, 2*y)\n",
    "\n",
    "# Parameters for gradient descent\n",
    "x_init, y_init = 10, 10\n",
    "learning_rate = 0.1\n",
    "num_iterations = 100\n",
    "\n",
    "# Perform gradient descent\n",
    "x_min, y_min, trajectory = gradient_descent(f_sphere, grad_f_sphere, x_init, y_init, learning_rate, num_iterations)\n",
    "\n",
    "# Plotting the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, Z, cmap='coolwarm', alpha=0.5)\n",
    "trajectory = np.array(trajectory)\n",
    "ax.plot(trajectory[:,0], trajectory[:,1], f_sphere(trajectory[:,0], trajectory[:,1]), 'r-o')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('function')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
